{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "target_variable = '_MICHD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fillna_cdc = pd.read_pickle('./dataset_filled_na.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "      <td>417762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.903639</td>\n",
       "      <td>2.590449</td>\n",
       "      <td>2639.447510</td>\n",
       "      <td>7.939549</td>\n",
       "      <td>3.996838</td>\n",
       "      <td>29.168953</td>\n",
       "      <td>7.825973</td>\n",
       "      <td>3.262343</td>\n",
       "      <td>18.235296</td>\n",
       "      <td>2.955518</td>\n",
       "      <td>...</td>\n",
       "      <td>1.976221</td>\n",
       "      <td>1.913475</td>\n",
       "      <td>1.530209</td>\n",
       "      <td>0.638768</td>\n",
       "      <td>0.357081</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.326830</td>\n",
       "      <td>3.098441</td>\n",
       "      <td>1.925379</td>\n",
       "      <td>34.277534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.295086</td>\n",
       "      <td>1.113423</td>\n",
       "      <td>902.930176</td>\n",
       "      <td>3.441724</td>\n",
       "      <td>2.880877</td>\n",
       "      <td>16.008047</td>\n",
       "      <td>7.593786</td>\n",
       "      <td>1.636949</td>\n",
       "      <td>29.922846</td>\n",
       "      <td>1.017982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337706</td>\n",
       "      <td>0.390049</td>\n",
       "      <td>1.197181</td>\n",
       "      <td>1.404142</td>\n",
       "      <td>0.869926</td>\n",
       "      <td>0.711291</td>\n",
       "      <td>0.823295</td>\n",
       "      <td>12.588753</td>\n",
       "      <td>0.494496</td>\n",
       "      <td>42.394764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2317.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2663.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3083.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9960.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              _MICHD        GENHLTH          _BMI5       _AGEG5YR  \\\n",
       "count  417762.000000  417762.000000  417762.000000  417762.000000   \n",
       "mean        1.903639       2.590449    2639.447510       7.939549   \n",
       "std         0.295086       1.113423     902.930176       3.441724   \n",
       "min         1.000000       0.000000       0.000000       1.000000   \n",
       "25%         2.000000       2.000000    2317.000000       6.000000   \n",
       "50%         2.000000       3.000000    2663.000000       8.000000   \n",
       "75%         2.000000       3.000000    3083.000000      11.000000   \n",
       "max         2.000000       9.000000    9960.000000      14.000000   \n",
       "\n",
       "             EMPLOY1         _STATE       SLEPTIM1        TETANUS  \\\n",
       "count  417762.000000  417762.000000  417762.000000  417762.000000   \n",
       "mean        3.996838      29.168953       7.825973       3.262343   \n",
       "std         2.880877      16.008047       7.593786       1.636949   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         1.000000      16.000000       6.000000       2.000000   \n",
       "50%         3.000000      28.000000       7.000000       3.000000   \n",
       "75%         7.000000      40.000000       8.000000       4.000000   \n",
       "max         9.000000      78.000000      99.000000       9.000000   \n",
       "\n",
       "             INCOME2        _EDUCAG      ...             CHCKIDNY  \\\n",
       "count  417762.000000  417762.000000      ...        417762.000000   \n",
       "mean       18.235296       2.955518      ...             1.976221   \n",
       "std        29.922846       1.017982      ...             0.337706   \n",
       "min         1.000000       1.000000      ...             1.000000   \n",
       "25%         5.000000       2.000000      ...             2.000000   \n",
       "50%         7.000000       3.000000      ...             2.000000   \n",
       "75%         8.000000       4.000000      ...             2.000000   \n",
       "max        99.000000       9.000000      ...             9.000000   \n",
       "\n",
       "            CHCSCNCR       CHECKUP1       _PNEUMO2        WRITTEN  \\\n",
       "count  417762.000000  417762.000000  417762.000000  417762.000000   \n",
       "mean        1.913475       1.530209       0.638768       0.357081   \n",
       "std         0.390049       1.197181       1.404142       0.869926   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       1.000000       0.000000       0.000000   \n",
       "50%         2.000000       1.000000       0.000000       0.000000   \n",
       "75%         2.000000       1.000000       1.000000       0.000000   \n",
       "max         9.000000       9.000000       9.000000       9.000000   \n",
       "\n",
       "            UNDRSTND       MEDADVIC        _PRACE1         DECIDE  \\\n",
       "count  417762.000000  417762.000000  417762.000000  417762.000000   \n",
       "mean        0.313066       0.326830       3.098441       1.925379   \n",
       "std         0.711291       0.823295      12.588753       0.494496   \n",
       "min         0.000000       0.000000       1.000000       1.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       0.000000       1.000000       2.000000   \n",
       "75%         0.000000       0.000000       1.000000       2.000000   \n",
       "max         9.000000       9.000000      99.000000       9.000000   \n",
       "\n",
       "            DRNK3GE5  \n",
       "count  417762.000000  \n",
       "mean       34.277534  \n",
       "std        42.394764  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%        88.000000  \n",
       "max        99.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casted_cdc = fillna_cdc.astype(np.float32)\n",
    "casted_cdc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can scale all the variables in the interval [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _MICHD  GENHLTH   _BMI5  _AGEG5YR  EMPLOY1  _STATE  SLEPTIM1  TETANUS  \\\n",
       "0     2.0      1.0  2053.0       5.0      1.0     1.0       5.0      3.0   \n",
       "1     2.0      2.0  2710.0       8.0      5.0     1.0       6.0      4.0   \n",
       "2     1.0      3.0  1997.0      13.0      7.0     1.0       9.0      4.0   \n",
       "3     2.0      3.0  2903.0      11.0      7.0     1.0       7.0      4.0   \n",
       "4     2.0      5.0  2018.0       1.0      1.0     1.0       6.0      4.0   \n",
       "\n",
       "   INCOME2  _EDUCAG    ...     CHCKIDNY  CHCSCNCR  CHECKUP1  _PNEUMO2  \\\n",
       "0      5.0      2.0    ...          2.0       2.0       1.0       0.0   \n",
       "1      7.0      2.0    ...          2.0       2.0       1.0       0.0   \n",
       "2      7.0      3.0    ...          2.0       1.0       1.0       1.0   \n",
       "3      7.0      4.0    ...          2.0       1.0       1.0       1.0   \n",
       "4     77.0      2.0    ...          2.0       2.0       1.0       0.0   \n",
       "\n",
       "   WRITTEN  UNDRSTND  MEDADVIC  _PRACE1  DECIDE  DRNK3GE5  \n",
       "0      1.0       1.0       1.0      1.0     2.0       0.0  \n",
       "1      2.0       1.0       1.0      1.0     2.0       0.0  \n",
       "2      1.0       1.0       1.0      1.0     2.0      88.0  \n",
       "3      1.0       1.0       1.0      1.0     2.0       0.0  \n",
       "4      1.0       2.0       1.0      1.0     2.0       0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casted_cdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = casted_cdc.drop(target_variable, axis=1)\n",
    "y = casted_cdc[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moved the target variable as last variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>_MICHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GENHLTH   _BMI5  _AGEG5YR  EMPLOY1  _STATE  SLEPTIM1  TETANUS  INCOME2  \\\n",
       "0      1.0  2053.0       5.0      1.0     1.0       5.0      3.0      5.0   \n",
       "1      2.0  2710.0       8.0      5.0     1.0       6.0      4.0      7.0   \n",
       "2      3.0  1997.0      13.0      7.0     1.0       9.0      4.0      7.0   \n",
       "3      3.0  2903.0      11.0      7.0     1.0       7.0      4.0      7.0   \n",
       "4      5.0  2018.0       1.0      1.0     1.0       6.0      4.0     77.0   \n",
       "\n",
       "   _EDUCAG  _PHYS14D   ...    CHCSCNCR  CHECKUP1  _PNEUMO2  WRITTEN  UNDRSTND  \\\n",
       "0      2.0       1.0   ...         2.0       1.0       0.0      1.0       1.0   \n",
       "1      2.0       1.0   ...         2.0       1.0       0.0      2.0       1.0   \n",
       "2      3.0       1.0   ...         1.0       1.0       1.0      1.0       1.0   \n",
       "3      4.0       1.0   ...         1.0       1.0       1.0      1.0       1.0   \n",
       "4      2.0       2.0   ...         2.0       1.0       0.0      1.0       2.0   \n",
       "\n",
       "   MEDADVIC  _PRACE1  DECIDE  DRNK3GE5  _MICHD  \n",
       "0       1.0      1.0     2.0       0.0     2.0  \n",
       "1       1.0      1.0     2.0       0.0     2.0  \n",
       "2       1.0      1.0     2.0      88.0     1.0  \n",
       "3       1.0      1.0     2.0       0.0     2.0  \n",
       "4       1.0      1.0     2.0       0.0     2.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_cdc = pd.concat([X, y], axis=1)\n",
    "concat_cdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_cdc = shuffle(concat_cdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(shuffled_cdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417762, 56)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cdc_np = scaler.transform(shuffled_cdc)\n",
    "transformed_cdc_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>_MICHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.351104</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307932</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.225703</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GENHLTH     _BMI5  _AGEG5YR  EMPLOY1    _STATE  SLEPTIM1  TETANUS  \\\n",
       "0  0.222222  0.351104  0.615385    0.000  0.623377  0.081633     0.00   \n",
       "1  0.333333  0.396386  0.384615    0.000  0.428571  0.061224     0.25   \n",
       "2  0.222222  0.307932  0.076923    0.625  0.337662  0.061224     0.00   \n",
       "3  0.222222  0.225703  0.692308    0.875  0.142857  0.010204     0.00   \n",
       "4  0.111111  0.000000  0.615385    0.750  0.467532  0.071429     0.00   \n",
       "\n",
       "    INCOME2  _EDUCAG  _PHYS14D   ...    CHCSCNCR  CHECKUP1  _PNEUMO2  \\\n",
       "0  0.061224    0.250     0.000   ...       0.000  0.111111  0.000000   \n",
       "1  1.000000    0.250     0.000   ...       0.125  0.111111  0.000000   \n",
       "2  0.061224    0.125     0.125   ...       0.125  0.111111  0.000000   \n",
       "3  0.775510    0.000     0.000   ...       0.125  0.111111  0.222222   \n",
       "4  1.000000    0.375     0.000   ...       0.125  0.111111  0.000000   \n",
       "\n",
       "    WRITTEN  UNDRSTND  MEDADVIC   _PRACE1  DECIDE  DRNK3GE5  _MICHD  \n",
       "0  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "1  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "2  0.111111  0.111111  0.111111  0.000000   0.125  0.010101     1.0  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "4  0.111111  0.111111  0.111111  0.010204   0.125  0.000000     1.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cdc = pd.DataFrame(transformed_cdc_np, columns=shuffled_cdc.columns)\n",
    "transformed_cdc.head()"
   ]
  },
  {
   "attachments": {
    "gan_diagram.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Inbalanced Data\n",
    "\n",
    "### Classical Approach\n",
    "\n",
    "Since the dataset is inbalanced we need to apply an oversampling technique to generate new samples for the less frequent class.\n",
    "[SMOTE: Synthetic Minority Over-sampling Technique](https://www.jair.org/media/953/live-953-2037-jair.pdf) is one of the most famous contribution to solve this problem. To then oversample, take a sample from the dataset, and consider its k nearest neighbors (in feature space). To create a synthetic data point, take the vector between one of those k neighbors, and the current data point. Multiply this vector by a random number x which lies between 0, and 1. Add this to the current data point to create the new, synthetic data point.\n",
    "\n",
    "### Generative Adversarial Network\n",
    "\n",
    "Generative Adversarial Networks (GANs) were [first reported](https://arxiv.org/abs/1406.2661 on in 2014 from Ian Goodfellow and others in Yoshua Bengio's lab. Since then, GANs have exploded in popularity. Here are a few examples to check out:\n",
    "\n",
    "- [Pix2Pix](https://affinelayer.com/pixsrv/)\n",
    "- [CycleGAN](https://github.com/junyanz/CycleGAN)\n",
    "\n",
    "The idea behind GANs is that you have two networks, a generator $G$ and a discriminator $D$, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it's received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistiguishable from real data to the discriminator.\n",
    "\n",
    "![gan_diagram.png](attachment:gan_diagram.png)\n",
    "\n",
    "We need to create an oversampler for '_MICHD' = 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAECCAYAAAACQYvcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15569cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformed_cdc[target_variable].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, optimizers, models, activations, losses\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_in_dim = 10\n",
    "gen_out_dim = X_new.shape[1]\n",
    "discr_inp_dim = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator(G_in, dense_dim=200, out_dim=50, lr=1e-3):\n",
    "    x_1 = layers.Dense(128)(G_in)\n",
    "    x_1 = layers.normalization.BatchNormalization()(x_1)\n",
    "    x_1 = layers.Activation('relu')(x_1)\n",
    "    \n",
    "    x_2 = layers.Dense(256)(x_1)\n",
    "    x_2 = layers.normalization.BatchNormalization()(x_2)\n",
    "    x_2 = layers.Activation('relu')(x_2)\n",
    "    \n",
    "    x_3 = layers.Dense(128)(x_2)\n",
    "    x_3 = layers.normalization.BatchNormalization()(x_3)\n",
    "    x_3 = layers.Activation('relu')(x_3)\n",
    "    \n",
    "    G_out = layers.Dense(out_dim, activation='relu')(x_3)\n",
    "    G = models.Model(G_in, G_out)\n",
    "    opt = optimizers.Adam()\n",
    "    G.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return G, G_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 55)                7095      \n",
      "=================================================================\n",
      "Total params: 76,471\n",
      "Trainable params: 75,447\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_in = layers.Input(shape=[gen_in_dim])\n",
    "G, G_out = build_generator(G_in, out_dim=gen_out_dim)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator(D_in, lr=1e-3, drate=.25, n_channels=50, conv_sz=5, leak=.2):\n",
    "    x = layers.Reshape((-1, 1))(D_in)\n",
    "    x = layers.Conv1D(n_channels, conv_sz, activation='relu')(x)\n",
    "    x = layers.Dropout(drate)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(n_channels)(x)\n",
    "    D_out = layers.Dense(2, activation='sigmoid')(x)\n",
    "    D = models.Model(D_in, D_out)\n",
    "    dopt = optimizers.Adam()\n",
    "    D.compile(loss='binary_crossentropy', optimizer=dopt)\n",
    "    return D, D_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 55, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 51, 50)            300       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 51, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2550)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                127550    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 127,952\n",
      "Trainable params: 127,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D_in = layers.Input(shape=[discr_inp_dim])\n",
    "D, D_out = build_discriminator(D_in)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained model: GAN\n",
    "\n",
    "Finally, we chain the two models into a GAN that will serve to train the generator while we freeze the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_trainability(model, trainable=False):\n",
    "    model.trainable = trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_gan(GAN_in, G, D):\n",
    "    set_trainability(D, False)\n",
    "    x = G(GAN_in)\n",
    "    GAN_out = D(x)\n",
    "    GAN = models.Model(GAN_in, GAN_out)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=G.optimizer)\n",
    "    return GAN, GAN_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "model_20 (Model)             (None, 55)                76471     \n",
      "_________________________________________________________________\n",
      "model_21 (Model)             (None, 2)                 127952    \n",
      "=================================================================\n",
      "Total params: 204,423\n",
      "Trainable params: 75,447\n",
      "Non-trainable params: 128,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN_in = layers.Input([gen_in_dim])\n",
    "GAN, GAN_out = make_gan(GAN_in, G, D)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now we did setup our models, we can train the models by alterning training the discriminator and the chained models.\n",
    "\n",
    "#### Pre-training\n",
    "\n",
    "Letâ€™s now generate some fake and real data and pre-train the discriminator before starting the gan. This also let us check if our compiled models correclty runs on our real and noisy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(n_samples, n_dims):\n",
    "    return np.random.uniform(size=(n_samples,n_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_and_gen(G, noise_dim, discr_dim, n_samples=10000):\n",
    "    XT = sample_data(n_samples=n_samples, n_dims=discr_dim)\n",
    "    XN_noise = np.random.uniform(0, 1, size=[n_samples, noise_dim])\n",
    "    XN = G.predict(XN_noise)\n",
    "    X = np.concatenate((XT, XN))\n",
    "    y = np.zeros((2*n_samples, 2))\n",
    "    y[:n_samples, 1] = 1\n",
    "    y[n_samples:, 0] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sample_data_and_gen(G, noise_dim=gen_in_dim, discr_dim=discr_inp_dim, n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 55)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(G, D, noise_dim, discr_dim, n_samples=10000, batch_size=32):\n",
    "    X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim, discr_dim=discr_dim)\n",
    "    set_trainability(D, True)\n",
    "    D.fit(X, y, epochs=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s - loss: 0.0139     \n"
     ]
    }
   ],
   "source": [
    "pretrain(G, D, noise_dim=gen_in_dim, discr_dim=discr_inp_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating training steps\n",
    "We can now train our GAN by alternating the training of the Discriminator and the training of the chained GAN model with Discriminatorâ€™s weights freezed.\n",
    "\n",
    "At first we need to filter the dataset to sample the real examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>_MICHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.351104</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307932</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.225703</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GENHLTH     _BMI5  _AGEG5YR  EMPLOY1    _STATE  SLEPTIM1  TETANUS  \\\n",
       "0  0.222222  0.351104  0.615385    0.000  0.623377  0.081633     0.00   \n",
       "1  0.333333  0.396386  0.384615    0.000  0.428571  0.061224     0.25   \n",
       "2  0.222222  0.307932  0.076923    0.625  0.337662  0.061224     0.00   \n",
       "3  0.222222  0.225703  0.692308    0.875  0.142857  0.010204     0.00   \n",
       "4  0.111111  0.000000  0.615385    0.750  0.467532  0.071429     0.00   \n",
       "\n",
       "    INCOME2  _EDUCAG  _PHYS14D   ...    CHCSCNCR  CHECKUP1  _PNEUMO2  \\\n",
       "0  0.061224    0.250     0.000   ...       0.000  0.111111  0.000000   \n",
       "1  1.000000    0.250     0.000   ...       0.125  0.111111  0.000000   \n",
       "2  0.061224    0.125     0.125   ...       0.125  0.111111  0.000000   \n",
       "3  0.775510    0.000     0.000   ...       0.125  0.111111  0.222222   \n",
       "4  1.000000    0.375     0.000   ...       0.125  0.111111  0.000000   \n",
       "\n",
       "    WRITTEN  UNDRSTND  MEDADVIC   _PRACE1  DECIDE  DRNK3GE5  _MICHD  \n",
       "0  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "1  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "2  0.111111  0.111111  0.111111  0.000000   0.125  0.010101     1.0  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     1.0  \n",
       "4  0.111111  0.111111  0.111111  0.010204   0.125  0.000000     1.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>_MICHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334137</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.252008</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.327711</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.275502</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297691</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GENHLTH     _BMI5  _AGEG5YR  EMPLOY1    _STATE  SLEPTIM1  TETANUS  \\\n",
       "9   0.333333  0.334137  0.384615    0.375  0.000000  0.051020    0.125   \n",
       "44  0.333333  0.252008  0.923077    0.750  0.636364  0.051020    0.375   \n",
       "46  0.333333  0.327711  0.615385    0.000  0.090909  0.071429    0.375   \n",
       "47  0.222222  0.275502  0.769231    0.750  0.714286  0.071429    0.750   \n",
       "56  0.333333  0.297691  0.769231    0.750  0.103896  0.061224    0.750   \n",
       "\n",
       "     INCOME2  _EDUCAG  _PHYS14D   ...    CHCSCNCR  CHECKUP1  _PNEUMO2  \\\n",
       "9   0.000000    0.125     0.250   ...       0.125  0.222222  0.000000   \n",
       "44  0.051020    0.375     0.125   ...       0.125  0.111111  0.111111   \n",
       "46  1.000000    0.375     0.000   ...       0.125  0.111111  0.000000   \n",
       "47  0.040816    0.125     0.000   ...       0.125  0.111111  0.111111   \n",
       "56  0.071429    0.250     0.000   ...       0.000  0.111111  0.111111   \n",
       "\n",
       "     WRITTEN  UNDRSTND  MEDADVIC   _PRACE1  DECIDE  DRNK3GE5  _MICHD  \n",
       "9   0.222222  0.222222  0.111111  0.010204   0.000  0.010101     0.0  \n",
       "44  0.000000  0.000000  0.000000  0.000000   0.125  0.000000     0.0  \n",
       "46  0.000000  0.000000  0.000000  0.000000   0.125  0.020202     0.0  \n",
       "47  0.000000  0.000000  0.000000  0.000000   0.125  0.888889     0.0  \n",
       "56  0.000000  0.000000  0.000000  0.000000   0.125  0.777778     0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_attack_df = transformed_cdc[transformed_cdc[target_variable] == 0.0]\n",
    "heart_attack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334137</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.252008</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.327711</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.020202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.275502</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297691</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GENHLTH     _BMI5  _AGEG5YR  EMPLOY1    _STATE  SLEPTIM1  TETANUS  \\\n",
       "9   0.333333  0.334137  0.384615    0.375  0.000000  0.051020    0.125   \n",
       "44  0.333333  0.252008  0.923077    0.750  0.636364  0.051020    0.375   \n",
       "46  0.333333  0.327711  0.615385    0.000  0.090909  0.071429    0.375   \n",
       "47  0.222222  0.275502  0.769231    0.750  0.714286  0.071429    0.750   \n",
       "56  0.333333  0.297691  0.769231    0.750  0.103896  0.061224    0.750   \n",
       "\n",
       "     INCOME2  _EDUCAG  _PHYS14D    ...     CHCKIDNY  CHCSCNCR  CHECKUP1  \\\n",
       "9   0.000000    0.125     0.250    ...        0.125     0.125  0.222222   \n",
       "44  0.051020    0.375     0.125    ...        0.125     0.125  0.111111   \n",
       "46  1.000000    0.375     0.000    ...        0.125     0.125  0.111111   \n",
       "47  0.040816    0.125     0.000    ...        0.125     0.125  0.111111   \n",
       "56  0.071429    0.250     0.000    ...        0.125     0.000  0.111111   \n",
       "\n",
       "    _PNEUMO2   WRITTEN  UNDRSTND  MEDADVIC   _PRACE1  DECIDE  DRNK3GE5  \n",
       "9   0.000000  0.222222  0.222222  0.111111  0.010204   0.000  0.010101  \n",
       "44  0.111111  0.000000  0.000000  0.000000  0.000000   0.125  0.000000  \n",
       "46  0.000000  0.000000  0.000000  0.000000  0.000000   0.125  0.020202  \n",
       "47  0.111111  0.000000  0.000000  0.000000  0.000000   0.125  0.888889  \n",
       "56  0.111111  0.000000  0.000000  0.000000  0.000000   0.125  0.777778  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_attack_drop_target_df = heart_attack_df.drop([target_variable], axis=1)\n",
    "heart_attack_drop_target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_data(n_samples):\n",
    "    return heart_attack_drop_target_df.sample(n_samples).values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_read_data_and_gen(G, noise_dim, n_samples=10000):\n",
    "    XT = sample_real_data(n_samples=n_samples)\n",
    "    XN_noise = np.random.uniform(0, 1, size=[n_samples, noise_dim])\n",
    "    XN = G.predict(XN_noise)\n",
    "    X = np.concatenate((XT, XN))\n",
    "    y = np.zeros((2*n_samples, 2))\n",
    "    y[:n_samples, 1] = 1\n",
    "    y[n_samples:, 0] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise(G, noise_dim, n_samples=10000):\n",
    "    X = np.random.uniform(0, 1, size=[n_samples, noise_dim])\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 1] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(GAN, G, D, noise_dim, epochs=500, n_samples=10000, batch_size=32, verbose=False, v_freq=50):\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    e_range = range(epochs)\n",
    "#     if verbose:\n",
    "#         e_range = tqdm(e_range)\n",
    "    for epoch in e_range:\n",
    "        X, y = sample_read_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        set_trainability(D, True)\n",
    "        d_loss.append(D.train_on_batch(X, y))\n",
    "        \n",
    "        X, y = sample_noise(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        set_trainability(D, False)\n",
    "        g_loss.append(GAN.train_on_batch(X, y))\n",
    "        if verbose and (epoch + 1) % v_freq == 0:\n",
    "            print(\"Epoch #{}: Generative Loss: {}, Discriminative Loss: {}\".format(epoch + 1, g_loss[-1], d_loss[-1]))\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: Generative Loss: 1.1000356181511961e-07, Discriminative Loss: 0.005386353936046362\n",
      "Epoch #10: Generative Loss: 1.2728001763662178e-07, Discriminative Loss: 0.0015258047496899962\n",
      "Epoch #15: Generative Loss: 2.2039264990780794e-07, Discriminative Loss: 0.0016171348979696631\n",
      "Epoch #20: Generative Loss: 2.036942703398381e-07, Discriminative Loss: 0.0024478051345795393\n",
      "Epoch #25: Generative Loss: 2.2525449594468228e-07, Discriminative Loss: 0.005005803424865007\n",
      "Epoch #30: Generative Loss: 1.9015894281437795e-07, Discriminative Loss: 0.015111343003809452\n",
      "Epoch #35: Generative Loss: 7.475093752873363e-07, Discriminative Loss: 0.02756485342979431\n",
      "Epoch #40: Generative Loss: 2.5761783035704866e-05, Discriminative Loss: 0.02867698296904564\n",
      "Epoch #45: Generative Loss: 3.805177766480483e-05, Discriminative Loss: 0.044054288417100906\n",
      "Epoch #50: Generative Loss: 1.6505484381923452e-05, Discriminative Loss: 0.052913598716259\n",
      "Epoch #55: Generative Loss: 3.833551818388514e-05, Discriminative Loss: 0.04906446859240532\n",
      "Epoch #60: Generative Loss: 5.4379808716475964e-05, Discriminative Loss: 0.0421903133392334\n",
      "Epoch #65: Generative Loss: 0.00017355581803712994, Discriminative Loss: 0.02574056386947632\n",
      "Epoch #70: Generative Loss: 0.0003131536941509694, Discriminative Loss: 0.019709963351488113\n",
      "Epoch #75: Generative Loss: 0.0008078939281404018, Discriminative Loss: 0.012557754293084145\n",
      "Epoch #80: Generative Loss: 0.00026663727476261556, Discriminative Loss: 0.009121625684201717\n",
      "Epoch #85: Generative Loss: 0.00015810913464520127, Discriminative Loss: 0.0075005460530519485\n",
      "Epoch #90: Generative Loss: 0.0001327614882029593, Discriminative Loss: 0.007055472582578659\n",
      "Epoch #95: Generative Loss: 9.96975286398083e-05, Discriminative Loss: 0.0063910093158483505\n",
      "Epoch #100: Generative Loss: 0.00017485029820818454, Discriminative Loss: 0.005772363860160112\n",
      "Epoch #105: Generative Loss: 0.00026823492953553796, Discriminative Loss: 0.004528344608843327\n",
      "Epoch #110: Generative Loss: 0.00010823848424479365, Discriminative Loss: 0.0041152313351631165\n",
      "Epoch #115: Generative Loss: 5.9705078456318006e-05, Discriminative Loss: 0.0040924097411334515\n",
      "Epoch #120: Generative Loss: 0.00019992588204331696, Discriminative Loss: 0.00406070239841938\n",
      "Epoch #125: Generative Loss: 9.828109614318237e-05, Discriminative Loss: 0.003983969334512949\n",
      "Epoch #130: Generative Loss: 6.31928924121894e-05, Discriminative Loss: 0.003933117724955082\n",
      "Epoch #135: Generative Loss: 9.886318730423227e-05, Discriminative Loss: 0.003821892663836479\n",
      "Epoch #140: Generative Loss: 2.705972110561561e-05, Discriminative Loss: 0.004574987571686506\n",
      "Epoch #145: Generative Loss: 0.0001139879459515214, Discriminative Loss: 0.005037532653659582\n",
      "Epoch #150: Generative Loss: 0.0001832918933359906, Discriminative Loss: 0.004857492633163929\n",
      "Epoch #155: Generative Loss: 0.00015027642075438052, Discriminative Loss: 0.00694740517064929\n",
      "Epoch #160: Generative Loss: 0.0005523876752704382, Discriminative Loss: 0.008946922607719898\n",
      "Epoch #165: Generative Loss: 0.0005229578237049282, Discriminative Loss: 0.008409046567976475\n",
      "Epoch #170: Generative Loss: 0.00026004723622463644, Discriminative Loss: 0.013504325412213802\n",
      "Epoch #175: Generative Loss: 0.0007441294728778303, Discriminative Loss: 0.01963956095278263\n",
      "Epoch #180: Generative Loss: 0.0004795699496753514, Discriminative Loss: 0.030398188158869743\n",
      "Epoch #185: Generative Loss: 0.0002831428428180516, Discriminative Loss: 0.03683463856577873\n",
      "Epoch #190: Generative Loss: 0.0003716487262863666, Discriminative Loss: 0.03931984677910805\n",
      "Epoch #195: Generative Loss: 0.00026190868811681867, Discriminative Loss: 0.03696224465966225\n",
      "Epoch #200: Generative Loss: 0.001810017740353942, Discriminative Loss: 0.03555062413215637\n"
     ]
    }
   ],
   "source": [
    "d_loss, g_loss = train(GAN, G, D, noise_dim=gen_in_dim, epochs=200, verbose=True, v_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x17ea25860>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEopVSPacCillKqR/weV1tiB9YiKDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ea0f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Generative Loss': g_loss,\n",
    "        'Discriminative Loss': d_loss,\n",
    "    }\n",
    ").plot(title='Training loss', logy=True)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the generator to create new examples. We want to generate at least 100k examples to make the dataset balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    377506\n",
       "0.0     40256\n",
       "Name: _MICHD, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cdc[target_variable].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_dataset(G, df, n_samples):\n",
    "    # generate n_samples\n",
    "    XN_noise = np.random.uniform(0, 1, size=[n_samples, gen_in_dim])\n",
    "    XN = G.predict(XN_noise)\n",
    "    # append the target variable\n",
    "    t = np.zeros((XN.shape[0],1))\n",
    "    # Append the new generated data to the existing dataframe\n",
    "    XN_appended = np.append(XN,t, axis=1)\n",
    "    XN_df = pd.DataFrame(XN_appended, columns=df.columns)\n",
    "    oversampled_df = XN_df.append(df)\n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oversampled_df = oversample_dataset(G, transformed_cdc, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417762, 56)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_cdc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427762, 56)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>_BMI5</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>TETANUS</th>\n",
       "      <th>INCOME2</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_PHYS14D</th>\n",
       "      <th>...</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>WRITTEN</th>\n",
       "      <th>UNDRSTND</th>\n",
       "      <th>MEDADVIC</th>\n",
       "      <th>_PRACE1</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>DRNK3GE5</th>\n",
       "      <th>_MICHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433103</td>\n",
       "      <td>1.093352</td>\n",
       "      <td>1.794026</td>\n",
       "      <td>2.369062</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.663572</td>\n",
       "      <td>1.893259</td>\n",
       "      <td>0.362785</td>\n",
       "      <td>0.193429</td>\n",
       "      <td>0.890923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057562</td>\n",
       "      <td>0.363684</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>0.433980</td>\n",
       "      <td>0.302726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872485</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>1.334107</td>\n",
       "      <td>2.130160</td>\n",
       "      <td>0.714181</td>\n",
       "      <td>0.431106</td>\n",
       "      <td>2.646604</td>\n",
       "      <td>0.673815</td>\n",
       "      <td>1.202521</td>\n",
       "      <td>0.686619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367252</td>\n",
       "      <td>0.250517</td>\n",
       "      <td>0.168362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460147</td>\n",
       "      <td>0.565857</td>\n",
       "      <td>0.597484</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.362725</td>\n",
       "      <td>1.229241</td>\n",
       "      <td>1.995849</td>\n",
       "      <td>2.349636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.602469</td>\n",
       "      <td>0.402746</td>\n",
       "      <td>0.317203</td>\n",
       "      <td>0.859202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290488</td>\n",
       "      <td>0.545059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.211033</td>\n",
       "      <td>0.883122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.780233</td>\n",
       "      <td>1.085056</td>\n",
       "      <td>1.865651</td>\n",
       "      <td>2.023071</td>\n",
       "      <td>0.537042</td>\n",
       "      <td>0.877120</td>\n",
       "      <td>2.725894</td>\n",
       "      <td>0.577512</td>\n",
       "      <td>1.126270</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069499</td>\n",
       "      <td>0.924295</td>\n",
       "      <td>0.504403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.273726</td>\n",
       "      <td>1.398840</td>\n",
       "      <td>1.651817</td>\n",
       "      <td>2.145727</td>\n",
       "      <td>0.951965</td>\n",
       "      <td>1.053476</td>\n",
       "      <td>2.220606</td>\n",
       "      <td>0.545901</td>\n",
       "      <td>0.947317</td>\n",
       "      <td>0.787847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275925</td>\n",
       "      <td>0.140096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.689730</td>\n",
       "      <td>0.376593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GENHLTH     _BMI5  _AGEG5YR   EMPLOY1    _STATE  SLEPTIM1   TETANUS  \\\n",
       "0  0.433103  1.093352  1.794026  2.369062  0.324431  0.663572  1.893259   \n",
       "1  0.872485  0.735751  1.334107  2.130160  0.714181  0.431106  2.646604   \n",
       "2  1.362725  1.229241  1.995849  2.349636  0.000000  0.000000  2.602469   \n",
       "3  1.780233  1.085056  1.865651  2.023071  0.537042  0.877120  2.725894   \n",
       "4  1.273726  1.398840  1.651817  2.145727  0.951965  1.053476  2.220606   \n",
       "\n",
       "    INCOME2   _EDUCAG  _PHYS14D   ...    CHCSCNCR  CHECKUP1  _PNEUMO2  \\\n",
       "0  0.362785  0.193429  0.890923   ...    0.000000  0.695081  0.000000   \n",
       "1  0.673815  1.202521  0.686619   ...    0.000000  0.000000  0.367252   \n",
       "2  0.402746  0.317203  0.859202   ...    0.290488  0.545059  0.000000   \n",
       "3  0.577512  1.126270  0.745223   ...    0.000000  0.802873  0.000000   \n",
       "4  0.545901  0.947317  0.787847   ...    0.000000  0.877546  0.000000   \n",
       "\n",
       "    WRITTEN  UNDRSTND  MEDADVIC   _PRACE1    DECIDE  DRNK3GE5  _MICHD  \n",
       "0  0.000000  0.057562  0.363684  0.047338  0.433980  0.302726     0.0  \n",
       "1  0.250517  0.168362  0.000000  0.460147  0.565857  0.597484     0.0  \n",
       "2  0.003440  0.000000  0.000000  0.406304  0.211033  0.883122     0.0  \n",
       "3  0.630896  0.058228  0.000000  0.069499  0.924295  0.504403     0.0  \n",
       "4  0.275925  0.140096  0.000000  0.203576  0.689730  0.376593     0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oversampled_df.to_pickle('./dataset_oversampled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_test(data):\n",
    "    shuffled_data = shuffle(data)\n",
    "    X = shuffled_data.drop([target_variable], axis=1).values\n",
    "    y = shuffled_data[target_variable].values\n",
    "    \n",
    "    train_end = round(len(X) * 0.7)\n",
    "    print('train end ', train_end)\n",
    "\n",
    "    X_train = X[:train_end]\n",
    "    y_train = y[:train_end]\n",
    "\n",
    "    X_test = X[train_end:]\n",
    "    y_test = y[train_end:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = create_train_test(transformed_cdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362433, 55)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155329, 55)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_base(sizes = [32, 64, 32]):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(sizes[0],input_shape=(X.shape[1],), activation=activations.relu))\n",
    "    if (len(sizes) > 1):\n",
    "        for size in sizes[1:]:\n",
    "            model.add(layers.Dense(size, activation=activations.relu))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation=activations.sigmoid))\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecute and Hyperparameters Tuning\n",
    "\n",
    "- To evaluate the architecture we are going to do experiments increasing the network size\n",
    "- Moreover, we are going to check if Dropout and Batch Normalization helps in the learning process.\n",
    "- Finally we are going to evaluate if the size of data generated by the generator improves the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_dropout(sizes = [32, 64, 32]):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(sizes[0],input_shape=(X.shape[1],), activation=activations.relu))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    if (len(sizes) > 1):\n",
    "        for size in sizes[1:]:\n",
    "            model.add(layers.Dense(size, activation=activations.relu))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation=activations.sigmoid))\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_batch_norm(sizes = [32, 64, 32]):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(sizes[0],input_shape=(X.shape[1],), activation=activations.relu))\n",
    "    model.add(layers.normalization.BatchNormalization())\n",
    "    if (len(sizes) > 1):\n",
    "        for size in sizes[1:]:\n",
    "            model.add(layers.Dense(size, activation=activations.relu))\n",
    "            model.add(layers.normalization.BatchNormalization())\n",
    "        \n",
    "    model.add(layers.Dense(1, activation=activations.sigmoid))\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_list =[\n",
    "    [16,32,16],\n",
    "    [32,64,32],\n",
    "    [64,128,64]\n",
    "]\n",
    "\n",
    "architectures = {\n",
    "    'base': build_model_base,\n",
    "    'dropout': build_model_dropout,\n",
    "    'batch_norm': build_model_batch_norm\n",
    "}\n",
    "\n",
    "oversamples = [0, 50000, 100000, 150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> (417762,56)\n",
      "train end  292433\n",
      "50000 -> (467762,56)\n",
      "train end  327433\n",
      "100000 -> (517762,56)\n",
      "train end  362433\n",
      "150000 -> (567762,56)\n",
      "train end  397433\n"
     ]
    }
   ],
   "source": [
    "oversampled_datesets = {}\n",
    "\n",
    "for sample_size in oversamples:\n",
    "    if sample_size == 0:\n",
    "        print('%d -> (%d,%d)' % (sample_size, *transformed_cdc.shape))\n",
    "        oversampled_datesets[sample_size] = create_train_test(transformed_cdc)\n",
    "    else:\n",
    "        df = oversample_dataset(G, transformed_cdc, sample_size)\n",
    "        print('%d -> (%d,%d)' % (sample_size, *df.shape))\n",
    "        oversampled_datesets[sample_size] = create_train_test(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing layer_conf:16_32_16_architecture:base_oversample:0\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_300 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 36s - loss: 0.2563 - acc: 0.9042 - val_loss: 0.2563 - val_acc: 0.9006\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 35s - loss: 0.2504 - acc: 0.9050 - val_loss: 0.2561 - val_acc: 0.9002\n",
      "125329/125329 [==============================] - 5s     \n",
      "processing layer_conf:16_32_16_architecture:base_oversample:50000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_304 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 43s - loss: 0.2324 - acc: 0.9129 - val_loss: 0.2249 - val_acc: 0.9135\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 41s - loss: 0.2245 - acc: 0.9151 - val_loss: 0.2226 - val_acc: 0.9157\n",
      "140096/140329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:base_oversample:100000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_308 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 49s - loss: 0.2100 - acc: 0.9215 - val_loss: 0.2014 - val_acc: 0.9246\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 45s - loss: 0.2015 - acc: 0.9232 - val_loss: 0.2000 - val_acc: 0.9242\n",
      "155329/155329 [==============================] - 7s     \n",
      "processing layer_conf:16_32_16_architecture:base_oversample:150000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_312 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 52s - loss: 0.1908 - acc: 0.9284 - val_loss: 0.1844 - val_acc: 0.9301\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 51s - loss: 0.1837 - acc: 0.9301 - val_loss: 0.1865 - val_acc: 0.9301\n",
      "169920/170329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:batch_norm_oversample:0\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_316 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,241\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 70s - loss: 0.2669 - acc: 0.9000 - val_loss: 0.2552 - val_acc: 0.8999\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 68s - loss: 0.2501 - acc: 0.9051 - val_loss: 0.2542 - val_acc: 0.8998\n",
      "125024/125329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:batch_norm_oversample:50000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_320 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,241\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294689/294689 [==============================] - 74s - loss: 0.2442 - acc: 0.9107 - val_loss: 0.2247 - val_acc: 0.9135\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 72s - loss: 0.2298 - acc: 0.9143 - val_loss: 0.2217 - val_acc: 0.9147\n",
      "140224/140329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:batch_norm_oversample:100000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_324 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,241\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 87s - loss: 0.2152 - acc: 0.9206 - val_loss: 0.2011 - val_acc: 0.9244\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 87s - loss: 0.2065 - acc: 0.9225 - val_loss: 0.1992 - val_acc: 0.9243\n",
      "155168/155329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:batch_norm_oversample:150000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_328 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,241\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 105s - loss: 0.1977 - acc: 0.9270 - val_loss: 0.1837 - val_acc: 0.9301\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 94s - loss: 0.1875 - acc: 0.9295 - val_loss: 0.1835 - val_acc: 0.9303\n",
      "170208/170329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:dropout_oversample:0\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_332 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 50s - loss: 0.2711 - acc: 0.9029 - val_loss: 0.2594 - val_acc: 0.8990\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 48s - loss: 0.2564 - acc: 0.9043 - val_loss: 0.2568 - val_acc: 0.8991\n",
      "124800/125329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:dropout_oversample:50000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_336 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 52s - loss: 0.2438 - acc: 0.9119 - val_loss: 0.2243 - val_acc: 0.9132\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 50s - loss: 0.2304 - acc: 0.9141 - val_loss: 0.2235 - val_acc: 0.9135\n",
      "140329/140329 [==============================] - 8s     \n",
      "processing layer_conf:16_32_16_architecture:dropout_oversample:100000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_340 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 55s - loss: 0.2199 - acc: 0.9209 - val_loss: 0.2026 - val_acc: 0.9234\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 55s - loss: 0.2070 - acc: 0.9225 - val_loss: 0.2020 - val_acc: 0.9234\n",
      "154688/155329 [============================>.] - ETA: 0sprocessing layer_conf:16_32_16_architecture:dropout_oversample:150000\n",
      "[16, 32, 16]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_344 (Dense)            (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 63s - loss: 0.2006 - acc: 0.9274 - val_loss: 0.1863 - val_acc: 0.9288\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 61s - loss: 0.1886 - acc: 0.9293 - val_loss: 0.1858 - val_acc: 0.9290\n",
      "170048/170329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:base_oversample:0\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_348 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 41s - loss: 0.2553 - acc: 0.9042 - val_loss: 0.2576 - val_acc: 0.9009\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 40s - loss: 0.2492 - acc: 0.9051 - val_loss: 0.2529 - val_acc: 0.9006\n",
      "124736/125329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:base_oversample:50000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_352 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 47s - loss: 0.2307 - acc: 0.9138 - val_loss: 0.2230 - val_acc: 0.9140\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 45s - loss: 0.2236 - acc: 0.9152 - val_loss: 0.2201 - val_acc: 0.9151\n",
      "140224/140329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:base_oversample:100000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_356 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 52s - loss: 0.2076 - acc: 0.9221 - val_loss: 0.2013 - val_acc: 0.9244\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 51s - loss: 0.2009 - acc: 0.9235 - val_loss: 0.2015 - val_acc: 0.9248\n",
      "155040/155329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:base_oversample:150000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_360 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 57s - loss: 0.1888 - acc: 0.9290 - val_loss: 0.1855 - val_acc: 0.9300\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 56s - loss: 0.1833 - acc: 0.9302 - val_loss: 0.1833 - val_acc: 0.9308\n",
      "169920/170329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:batch_norm_oversample:0\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_364 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,529\n",
      "Trainable params: 6,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263189/263189 [==============================] - 65s - loss: 0.2645 - acc: 0.9003 - val_loss: 0.2575 - val_acc: 0.9006\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 63s - loss: 0.2506 - acc: 0.9047 - val_loss: 0.2547 - val_acc: 0.8993\n",
      "124992/125329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:batch_norm_oversample:50000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_368 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,529\n",
      "Trainable params: 6,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 76s - loss: 0.2382 - acc: 0.9120 - val_loss: 0.2224 - val_acc: 0.9142\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 78s - loss: 0.2279 - acc: 0.9146 - val_loss: 0.2206 - val_acc: 0.9143\n",
      "139936/140329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:batch_norm_oversample:100000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_372 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,529\n",
      "Trainable params: 6,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 88s - loss: 0.2129 - acc: 0.9214 - val_loss: 0.2006 - val_acc: 0.9241\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 83s - loss: 0.2066 - acc: 0.9225 - val_loss: 0.1991 - val_acc: 0.9250\n",
      "154848/155329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:batch_norm_oversample:150000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_376 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,529\n",
      "Trainable params: 6,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 102s - loss: 0.1962 - acc: 0.9280 - val_loss: 0.1836 - val_acc: 0.9296\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 99s - loss: 0.1879 - acc: 0.9296 - val_loss: 0.1825 - val_acc: 0.9309\n",
      "170208/170329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:dropout_oversample:0\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_380 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 51s - loss: 0.2627 - acc: 0.9042 - val_loss: 0.2561 - val_acc: 0.8990\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 48s - loss: 0.2533 - acc: 0.9043 - val_loss: 0.2565 - val_acc: 0.8993\n",
      "125152/125329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:dropout_oversample:50000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_384 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 54s - loss: 0.2374 - acc: 0.9131 - val_loss: 0.2260 - val_acc: 0.9137\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 52s - loss: 0.2279 - acc: 0.9145 - val_loss: 0.2209 - val_acc: 0.9147\n",
      "140032/140329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:dropout_oversample:100000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_388 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_390 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 61s - loss: 0.2147 - acc: 0.9212 - val_loss: 0.2033 - val_acc: 0.9234\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 60s - loss: 0.2054 - acc: 0.9229 - val_loss: 0.2005 - val_acc: 0.9240\n",
      "155136/155329 [============================>.] - ETA: 0sprocessing layer_conf:32_64_32_architecture:dropout_oversample:150000\n",
      "[32, 64, 32]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_392 (Dense)            (None, 32)                1792      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,017\n",
      "Trainable params: 6,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 68s - loss: 0.1955 - acc: 0.9282 - val_loss: 0.1856 - val_acc: 0.9286\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 66s - loss: 0.1868 - acc: 0.9295 - val_loss: 0.1840 - val_acc: 0.9288\n",
      "169888/170329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:base_oversample:0\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_396 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 42s - loss: 0.2547 - acc: 0.9044 - val_loss: 0.2564 - val_acc: 0.9009\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 43s - loss: 0.2483 - acc: 0.9055 - val_loss: 0.2563 - val_acc: 0.9005\n",
      "125248/125329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:base_oversample:50000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_400 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 51s - loss: 0.2300 - acc: 0.9138 - val_loss: 0.2233 - val_acc: 0.9137\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 49s - loss: 0.2237 - acc: 0.9154 - val_loss: 0.2223 - val_acc: 0.9152\n",
      "139744/140329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:base_oversample:100000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_404 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 58s - loss: 0.2066 - acc: 0.9222 - val_loss: 0.2036 - val_acc: 0.9236\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 54s - loss: 0.2011 - acc: 0.9235 - val_loss: 0.1994 - val_acc: 0.9245\n",
      "154560/155329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:base_oversample:150000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_408 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_410 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 63s - loss: 0.1881 - acc: 0.9294 - val_loss: 0.1861 - val_acc: 0.9293\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 62s - loss: 0.1831 - acc: 0.9304 - val_loss: 0.1824 - val_acc: 0.9305\n",
      "169888/170329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:batch_norm_oversample:0\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_412 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 20,737\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 77s - loss: 0.2622 - acc: 0.9015 - val_loss: 0.2540 - val_acc: 0.9006\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 72s - loss: 0.2495 - acc: 0.9051 - val_loss: 0.2547 - val_acc: 0.8992\n",
      "125152/125329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:batch_norm_oversample:50000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_416 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 20,737\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 81s - loss: 0.2372 - acc: 0.9123 - val_loss: 0.2234 - val_acc: 0.9144\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 77s - loss: 0.2276 - acc: 0.9147 - val_loss: 0.2203 - val_acc: 0.9149\n",
      "140192/140329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:batch_norm_oversample:100000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_420 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 20,737\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 89s - loss: 0.2130 - acc: 0.9210 - val_loss: 0.2015 - val_acc: 0.9241\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 87s - loss: 0.2065 - acc: 0.9223 - val_loss: 0.1997 - val_acc: 0.9252\n",
      "155296/155329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:batch_norm_oversample:150000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_424 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 20,737\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 102s - loss: 0.1936 - acc: 0.9284 - val_loss: 0.1841 - val_acc: 0.9303\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 99s - loss: 0.1878 - acc: 0.9292 - val_loss: 0.1839 - val_acc: 0.9297\n",
      "170304/170329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:dropout_oversample:0\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_428 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 263189 samples, validate on 29244 samples\n",
      "Epoch 1/2\n",
      "263189/263189 [==============================] - 49s - loss: 0.2600 - acc: 0.9041 - val_loss: 0.2583 - val_acc: 0.8997\n",
      "Epoch 2/2\n",
      "263189/263189 [==============================] - 47s - loss: 0.2522 - acc: 0.9047 - val_loss: 0.2605 - val_acc: 0.9010\n",
      "124640/125329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:dropout_oversample:50000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_432 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 294689 samples, validate on 32744 samples\n",
      "Epoch 1/2\n",
      "294689/294689 [==============================] - 56s - loss: 0.2349 - acc: 0.9132 - val_loss: 0.2234 - val_acc: 0.9135\n",
      "Epoch 2/2\n",
      "294689/294689 [==============================] - 54s - loss: 0.2266 - acc: 0.9146 - val_loss: 0.2232 - val_acc: 0.9142\n",
      "140320/140329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:dropout_oversample:100000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_436 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 326189 samples, validate on 36244 samples\n",
      "Epoch 1/2\n",
      "326189/326189 [==============================] - 62s - loss: 0.2106 - acc: 0.9221 - val_loss: 0.2018 - val_acc: 0.9235\n",
      "Epoch 2/2\n",
      "326189/326189 [==============================] - 60s - loss: 0.2039 - acc: 0.9230 - val_loss: 0.2006 - val_acc: 0.9243\n",
      "154784/155329 [============================>.] - ETA: 0sprocessing layer_conf:64_128_64_architecture:dropout_oversample:150000\n",
      "[64, 128, 64]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_440 (Dense)            (None, 64)                3584      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 357689 samples, validate on 39744 samples\n",
      "Epoch 1/2\n",
      "357689/357689 [==============================] - 69s - loss: 0.1923 - acc: 0.9287 - val_loss: 0.1911 - val_acc: 0.9288\n",
      "Epoch 2/2\n",
      "357689/357689 [==============================] - 66s - loss: 0.1858 - acc: 0.9298 - val_loss: 0.1850 - val_acc: 0.9303\n",
      "169984/170329 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "generated_models = {}\n",
    "histories = {}\n",
    "evaluations = {}\n",
    "\n",
    "for layers_conf in layers_list:\n",
    "    for architecture, build_model in architectures.items():\n",
    "        for n_sample, v in oversampled_datesets.items():\n",
    "            key = \"layer_conf:%s_architecture:%s_oversample:%d\" % ('_'.join(str(e) for e in layers_conf), architecture, n_sample)\n",
    "            print('processing', key) \n",
    "            X_train, y_train, X_test, y_test = v\n",
    "            print(layers_conf)\n",
    "            model = build_model(layers_conf)\n",
    "            generated_models[key] = model\n",
    "            model.summary()\n",
    "            \n",
    "            histories[key] = model.fit(X_train, y_train, validation_split=0.1, epochs=2)\n",
    "            evaluations[key] = model.evaluate(X_test, y_test)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the Validation Set\n",
    "\n",
    "From the experiment ran above we can see that:\n",
    "- oversampling the dataset with generated from the generator network impoves the accuracy on the validation set\n",
    "- increasing the size of the network increase the accuracy of the network\n",
    "\n",
    "The best results on the validation set are obtained on the configuration:\n",
    "- layer_conf = [32,64,32]\n",
    "- architecture = batch_norm \n",
    "- oversample = 150000 \n",
    "\n",
    "val_acc: 0.9309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = {k:v[1] for k,v in evaluations.items()}\n",
    "sorted_test_accuracies  = sorted(test_accuracies.items(), key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration=layer_conf:16_32_16_architecture:batch_norm_oversample:150000 accuracy=0.9303\n",
      "configuration=layer_conf:32_64_32_architecture:base_oversample:150000 accuracy=0.9303\n",
      "configuration=layer_conf:32_64_32_architecture:batch_norm_oversample:150000 accuracy=0.9303\n",
      "configuration=layer_conf:64_128_64_architecture:dropout_oversample:150000 accuracy=0.9301\n",
      "configuration=layer_conf:64_128_64_architecture:base_oversample:150000 accuracy=0.9301\n",
      "configuration=layer_conf:16_32_16_architecture:base_oversample:150000 accuracy=0.9297\n",
      "configuration=layer_conf:64_128_64_architecture:batch_norm_oversample:150000 accuracy=0.9295\n",
      "configuration=layer_conf:16_32_16_architecture:dropout_oversample:150000 accuracy=0.9291\n",
      "configuration=layer_conf:32_64_32_architecture:dropout_oversample:150000 accuracy=0.9289\n",
      "configuration=layer_conf:32_64_32_architecture:batch_norm_oversample:100000 accuracy=0.9235\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted_test_accuracies[:10]:\n",
    "    print('configuration=%s accuracy=%.4f' % (k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results for the test set are obtained with:\n",
    "\n",
    "**Accuracy=0.9303**\n",
    "\n",
    "- layer_conf = [16,32,16]\n",
    "- architecture = batch_norm \n",
    "- oversample = 150000\n",
    "\n",
    "\n",
    "- layer_conf = [32,64,32]\n",
    "- architecture = base \n",
    "- oversample = 150000 \n",
    "\n",
    "- layer_conf = [32,64,32]\n",
    "- architecture = batch_norm \n",
    "- oversample = 150000 \n",
    "\n",
    "**Accuracy=0.9301**\n",
    "\n",
    "- layer_conf = [64,128,64]\n",
    "- architecture = dropout \n",
    "- oversample = 150000\n",
    "\n",
    "\n",
    "- layer_conf = [64,128,64]\n",
    "- architecture = base \n",
    "- oversample = 150000\n",
    "\n",
    "\n",
    "Thus we can conlude that:\n",
    "1. The GAN used to create a Generator improved the accuray of the network\n",
    "2. Batch Normalization was useful for some configurations\n",
    "3. With the maximum size of the network the Dropout was useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step will be to generate a new network trained for more epochs on all the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
